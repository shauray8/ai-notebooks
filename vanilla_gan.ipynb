{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import imshow, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST(\n",
    "    root = \"./data\", train = True, transform = torchvision.transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[.5],std=[.5])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=mnist, batch_size=64, \n",
    "                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,(a,b) in enumerate(data_loader):\n",
    "    plt.imshow(a[0].reshape(28,28))\n",
    "    print(b[0].item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Simple Discriminator w/ MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, num_classes=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 512),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(256, num_classes),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_ = x.view(x.size(0), -1)\n",
    "        y_ = self.layer(y_)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_size=100, num_classes=784):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size,128),\n",
    "            torch.nn.LeakyReLU(.2),\n",
    "            torch.nn.Linear(128,256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.LeakyReLU(.2),\n",
    "            torch.nn.Linear(256,512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(1024, num_classes),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y_ = self.layer(x)\n",
    "        y_ = y_.view(x.size(0),1,28,28)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_noise = 100\n",
    "n_critic = 1\n",
    "step = 0\n",
    "import os\n",
    "if not os.path.exists('samples'):\n",
    "    os.makedirs('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sample_image(G, n_noise):\n",
    "    \"\"\"\n",
    "        save sample 100 images\n",
    "    \"\"\"\n",
    "    z = torch.randn(100, n_noise).to('cuda')\n",
    "    y_hat = G(z).view(100, 28, 28) # (100, 28, 28)\n",
    "    result = y_hat.cpu().data.numpy()\n",
    "    img = np.zeros([280, 280])\n",
    "    for j in range(10):\n",
    "        img[j*28:(j+1)*28] = np.concatenate([x for x in result[j*10:(j+1)*10]], axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to('cuda')\n",
    "G = Generator(n_noise).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCELoss()\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr = 0.0002, betas=(.5,.999))\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr = 0.0002, betas=(.5,.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_labels = torch.ones(64,1).to('cuda')\n",
    "D_fakes = torch.zeros(64,1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20, Step: 18739, D Loss: 1.3729674816131592, G Loss: 0.8601198196411133: 100%|██████████| 20/20 [17:04<00:00, 51.23s/it] \n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "\n",
    "MODEL_NAME = 'VanillaGAN'\n",
    "epochs = 20\n",
    "for epoch in (l := trange(epochs)):\n",
    "    for _, (images, _) in enumerate(data_loader):\n",
    "        x = images.to('cuda')\n",
    "        x_outputs = D(x)\n",
    "        D_x_loss = loss_function(x_outputs, D_labels)\n",
    "        \n",
    "        z = torch.randn(64, n_noise).to('cuda')\n",
    "        z_outputs = D(G(z))\n",
    "        D_z_loss = loss_function(z_outputs, D_fakes)\n",
    "        D_loss = D_x_loss + D_z_loss\n",
    "        \n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        \n",
    "        if step % n_critic == 0:\n",
    "            z = torch.randn(batch_size, n_noise).to('cuda')\n",
    "            z_outputs = D(G(z))\n",
    "            G_loss = loss_function(z_outputs, D_labels)\n",
    "            \n",
    "            G.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_opt.step()\n",
    "        l.set_description('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, epochs, step, D_loss.item(), G_loss.item()))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            G.eval()\n",
    "            img = get_sample_image(G, n_noise)\n",
    "            imsave('samples/{}_step{}.jpg'.format(MODEL_NAME, str(step).zfill(3)), img, cmap='gray')\n",
    "            G.train()\n",
    "        \n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
